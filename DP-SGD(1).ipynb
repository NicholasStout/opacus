{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cd7e386",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "MAX_GRAD_NORM = 1.2\n",
    "EPSILON = 50.0\n",
    "DELTA = 1e-10\n",
    "EPOCHS = 3\n",
    "\n",
    "LR = 1e-3\n",
    "\n",
    "BATCH_SIZE = 120\n",
    "MAX_PHYSICAL_BATCH_SIZE = 256\n",
    "from torchvision.models.mobilenet import mobilenet_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e0ffb9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "50000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST, CIFAR10\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "\n",
    "DATA_ROOT = '../mnist'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = CIFAR10(\n",
    "    root=DATA_ROOT, train=True, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "test_dataset = MNIST(\n",
    "    root=DATA_ROOT, train=False, download=True, transform=transform)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "print(len(train_dataset))\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "images[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40e3632a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from opacus.utils.batch_memory_manager import BatchMemoryManager\n",
    "\n",
    "\n",
    "def train(model, train_loader, optimizer, epoch, device):\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    losses = []\n",
    "    top1_acc = []\n",
    "    \n",
    "    with BatchMemoryManager(\n",
    "        data_loader=train_loader, \n",
    "        max_physical_batch_size=MAX_PHYSICAL_BATCH_SIZE, \n",
    "        optimizer=optimizer\n",
    "    ) as memory_safe_data_loader:\n",
    "\n",
    "        for i, (images, target) in enumerate(memory_safe_data_loader):   \n",
    "            optimizer.zero_grad()\n",
    "            images = images.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            preds = np.argmax(output.detach().cpu().numpy(), axis=1)\n",
    "            labels = target.detach().cpu().numpy()\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc = accuracy(preds, labels)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            top1_acc.append(acc)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "\n",
    "            if (i+1) % 200 == 0:\n",
    "                epsilon = privacy_engine.get_epsilon(DELTA)\n",
    "                print(\n",
    "                    f\"\\tTrain Epoch: {epoch} \\t\"\n",
    "                    f\"Loss: {np.mean(losses):.6f} \"\n",
    "                    f\"Acc@1: {np.mean(top1_acc) * 100:.6f} \"\n",
    "                    f\"(ε = {epsilon:.5f}, δ = {DELTA})\"\n",
    "                )\n",
    "    return np.mean(top1_acc), epsilon\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9d41576",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(model, test_loader, device):\n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    losses = []\n",
    "    top1_acc = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, target in test_loader:\n",
    "            images = images.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "            preds = np.argmax(output.detach().cpu().numpy(), axis=1)\n",
    "            labels = target.detach().cpu().numpy()\n",
    "            acc = accuracy(preds, labels)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            top1_acc.append(acc)\n",
    "\n",
    "    top1_avg = np.mean(top1_acc)\n",
    "\n",
    "    print(\n",
    "        f\"\\tTest set:\"\n",
    "        f\"Loss: {np.mean(losses):.6f} \"\n",
    "        f\"Acc: {top1_avg * 100:.6f} \"\n",
    "    )\n",
    "    return np.mean(top1_acc)\n",
    "\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "report = []\n",
    "\n",
    "def accuracy(preds, labels):\n",
    "    return (preds == labels).mean()\n",
    "\n",
    "#for epoch in tqdm(range(EPOCHS), desc=\"Epoch\", unit=\"epoch\"):\n",
    "#    results = train(model, train_loader, optimizer, epoch + 1, device)\n",
    "#    report.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "839fe75c-8c8b-464d-ab0d-ecbe8a1c18d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from opacus import PrivacyEngine\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "from opacus.validators import ModuleValidator\n",
    "model = models.resnet18(num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f41fa37-57a1-44a9-84b4-5615eda28fc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "G_h =['eps_check','distortion','clip','q','k','theta']\n",
    "GU_h =['eps_check','distortion','clip','q', 'a', 'b', 'k','theta', 'M']\n",
    "#G250 = pd.read_csv(\"../arguments/G250_values.csv\", names = G_h)\n",
    "#GU250 = pd.read_csv(\"../arguments/GU_10Evalues.csv\", names=GU_h)\n",
    "#N250 = pd.read_csv(\"../arguments/N250_values.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e49da3a2-f179-4029-b735-e7440d69e051",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>eps_check</th>\n",
       "      <th>distortion</th>\n",
       "      <th>clip</th>\n",
       "      <th>q</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>k</th>\n",
       "      <th>theta</th>\n",
       "      <th>M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>12695</td>\n",
       "      <td>4.944675</td>\n",
       "      <td>3.215399e-01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>4.372430</td>\n",
       "      <td>0.922194</td>\n",
       "      <td>1322.354424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>31391</td>\n",
       "      <td>4.944952</td>\n",
       "      <td>3.215399e-01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>4.372430</td>\n",
       "      <td>0.922194</td>\n",
       "      <td>1322.354866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>15386</td>\n",
       "      <td>4.969609</td>\n",
       "      <td>5.262761e-01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>19.393939</td>\n",
       "      <td>0.103303</td>\n",
       "      <td>68.912626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>12692</td>\n",
       "      <td>4.961639</td>\n",
       "      <td>6.670193e-01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>4.372430</td>\n",
       "      <td>0.444548</td>\n",
       "      <td>82.611636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>31388</td>\n",
       "      <td>4.961948</td>\n",
       "      <td>6.670193e-01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>4.372430</td>\n",
       "      <td>0.444548</td>\n",
       "      <td>82.611955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>22043</td>\n",
       "      <td>4.942968</td>\n",
       "      <td>5.980840e+06</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>4.372430</td>\n",
       "      <td>0.922194</td>\n",
       "      <td>1322.351692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>24734</td>\n",
       "      <td>4.967708</td>\n",
       "      <td>5.980840e+06</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>19.393939</td>\n",
       "      <td>0.103303</td>\n",
       "      <td>68.910675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>22040</td>\n",
       "      <td>4.959732</td>\n",
       "      <td>5.980840e+06</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>4.372430</td>\n",
       "      <td>0.444548</td>\n",
       "      <td>82.609668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>3347</td>\n",
       "      <td>4.942726</td>\n",
       "      <td>6.815280e+06</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>4.372430</td>\n",
       "      <td>0.922194</td>\n",
       "      <td>1322.351305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>6038</td>\n",
       "      <td>4.967439</td>\n",
       "      <td>6.815280e+06</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>19.393939</td>\n",
       "      <td>0.103303</td>\n",
       "      <td>68.910399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>3344</td>\n",
       "      <td>4.959461</td>\n",
       "      <td>6.815281e+06</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>4.372430</td>\n",
       "      <td>0.444548</td>\n",
       "      <td>82.609390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  eps_check    distortion  clip      q        a         b  \\\n",
       "598  12695   4.944675  3.215399e-01   0.1  0.005  0.00001  0.000011   \n",
       "599  31391   4.944952  3.215399e-01   0.1  0.005  0.00001  0.000013   \n",
       "606  15386   4.969609  5.262761e-01   0.1  0.005  0.00001  0.000011   \n",
       "602  12692   4.961639  6.670193e-01   0.1  0.005  0.00001  0.000011   \n",
       "603  31388   4.961948  6.670193e-01   0.1  0.005  0.00001  0.000013   \n",
       "597  22043   4.942968  5.980840e+06   0.1  0.005  0.00000  0.000011   \n",
       "605  24734   4.967708  5.980840e+06   0.1  0.005  0.00000  0.000011   \n",
       "601  22040   4.959732  5.980840e+06   0.1  0.005  0.00000  0.000011   \n",
       "596   3347   4.942726  6.815280e+06   0.1  0.005  0.00000  0.000010   \n",
       "604   6038   4.967439  6.815280e+06   0.1  0.005  0.00000  0.000010   \n",
       "600   3344   4.959461  6.815281e+06   0.1  0.005  0.00000  0.000010   \n",
       "\n",
       "             k     theta            M  \n",
       "598   4.372430  0.922194  1322.354424  \n",
       "599   4.372430  0.922194  1322.354866  \n",
       "606  19.393939  0.103303    68.912626  \n",
       "602   4.372430  0.444548    82.611636  \n",
       "603   4.372430  0.444548    82.611955  \n",
       "597   4.372430  0.922194  1322.351692  \n",
       "605  19.393939  0.103303    68.910675  \n",
       "601   4.372430  0.444548    82.609668  \n",
       "596   4.372430  0.922194  1322.351305  \n",
       "604  19.393939  0.103303    68.910399  \n",
       "600   4.372430  0.444548    82.609390  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPSILON = 5\n",
    "import pandas as pd\n",
    "GU_h =['eps_check','distortion','clip','q', 'a', 'b', 'k','theta', 'M']\n",
    "GU250 = pd.read_csv(\"../arguments/GUEvalues.csv\", names=GU_h)\n",
    "GU250 = GU250.sort_values(\"eps_check\")\n",
    "GU250.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "GU250 = GU250.dropna()\n",
    "GU250 = GU250.reset_index()\n",
    "GU250.loc[(GU250['eps_check']  <= EPSILON) & (GU250['eps_check']  > EPSILON-0.1)].sort_values(\"distortion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5a4e6b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "69313",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/indexes/range.py:414\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 414\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_range\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[0;31mValueError\u001b[0m: 69313 is not in range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mGU250\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps_check\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m69313\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/series.py:1040\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1040\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/series.py:1156\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1156\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/pandas/core/indexes/range.py:416\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_range\u001b[38;5;241m.\u001b[39mindex(new_key)\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 416\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 69313"
     ]
    }
   ],
   "source": [
    "GU250['eps_check'][69313]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e60f63c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>eps_check</th>\n",
       "      <th>distortion</th>\n",
       "      <th>clip</th>\n",
       "      <th>q</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>k</th>\n",
       "      <th>theta</th>\n",
       "      <th>M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index, eps_check, distortion, clip, q, a, b, k, theta, M]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GU250.loc[(GU250['eps_check']  <= 0.5) & (GU250['eps_check']  > 0.49)].sort_values(\"distortion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94812723",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.922193863671697\n",
      "Begin training 598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/knil/Documents/NextCloud/RAstuff/opacus/opacus/privacy_engine.py:100: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3be3baa40a3c4961a2e86596082ec1d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/10 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/knil/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1373: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected number of channels in input to be divisible by num_groups, but got input of shape [208, 28, 28, 28] and num_groups=32",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 93\u001b[0m\n\u001b[1;32m     90\u001b[0m plrv_report_ep \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(EPOCHS), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m\"\u001b[39m, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 93\u001b[0m     acc, ep \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m     plrv_report_acc\u001b[38;5;241m.\u001b[39mappend(acc)\n\u001b[1;32m     95\u001b[0m     plrv_report_ep\u001b[38;5;241m.\u001b[39mappend(ep)\n",
      "Cell \u001b[0;32mIn[3], line 25\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, epoch, device)\u001b[0m\n\u001b[1;32m     22\u001b[0m target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# compute output\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, target)\n\u001b[1;32m     28\u001b[0m preds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(output\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/NextCloud/RAstuff/opacus/opacus/grad_sample/grad_sample_module.py:149\u001b[0m, in \u001b[0;36mGradSampleModule.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torchvision/models/resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torchvision/models/resnet.py:269\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;66;03m# See note [TorchScript super()]\u001b[39;00m\n\u001b[1;32m    268\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n\u001b[0;32m--> 269\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m    271\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxpool(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1582\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1580\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1582\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1584\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1585\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1586\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1587\u001b[0m     ):\n\u001b[1;32m   1588\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/modules/normalization.py:287\u001b[0m, in \u001b[0;36mGroupNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/nn/functional.py:2588\u001b[0m, in \u001b[0;36mgroup_norm\u001b[0;34m(input, num_groups, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2586\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected at least 2 dimensions for input tensor but received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2587\u001b[0m _verify_batch_size([\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m num_groups, num_groups] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m2\u001b[39m:]))\n\u001b[0;32m-> 2588\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected number of channels in input to be divisible by num_groups, but got input of shape [208, 28, 28, 28] and num_groups=32"
     ]
    }
   ],
   "source": [
    "acc_plrv_2 = []\n",
    "from torchvision.models.mobilenet import mobilenet_v2\n",
    "from transformers import ViTForImageClassification, ViTConfig\n",
    "for i in [598]:\n",
    "    torch.cuda.empty_cache()\n",
    "    args ={\n",
    "        \"a1\":1,\n",
    "        \"a3\":1,\n",
    "        \"a4\":1,\n",
    "        \"lam\":1,\n",
    "        \"moment\":1,\n",
    "        \"theta\":GU250['theta'][i],\n",
    "        'k':GU250['k'][i],\n",
    "        'mu':0,\n",
    "        'sigma':0.5,\n",
    "        'a':GU250['a'][i],\n",
    "        'b':GU250['b'][i],\n",
    "        'u':1,\n",
    "        'l':0.1,\n",
    "        'epsilon':1,\n",
    "        'max_grad_norm': GU250['clip'][i],\n",
    "        'gamma':True,\n",
    "        'uniform':True,\n",
    "        'truncnorm':False,\n",
    "    }\n",
    "    print(GU250['theta'][i])\n",
    "    EPOCHS = 10\n",
    "    BATCH_SIZE = 200\n",
    "    #print()\n",
    "    from torchvision.datasets import MNIST\n",
    "    import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "\n",
    "    DATA_ROOT = '../mnist'\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    train_dataset = MNIST(\n",
    "        root=DATA_ROOT, train=True, download=True, transform=transform)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "    )\n",
    "\n",
    "    test_dataset = MNIST(\n",
    "        root=DATA_ROOT, train=False, download=True, transform=transform)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    \n",
    "    #gen_args = find_values(15, i)\n",
    "    runs = []\n",
    "    trun = []\n",
    "\n",
    "    model = models.resnet18(num_classes=10)\n",
    "    #model.classifier[1] = torch.nn.Linear(in_features=model.classifier[1].in_features, out_features=10)\n",
    "    model.conv1 = nn.Conv2d(1, 28, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    #model.load_state_dict(dic)\n",
    "    #model.train()\n",
    "\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = ModuleValidator.fix(model)\n",
    "    model = model.to(device)\n",
    "\n",
    "    privacy_engine = PrivacyEngine(accountant = 'rdp_plrv')\n",
    "\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=LR)\n",
    "    print(\"Begin training \" + str(i))\n",
    "    model, optimizer, train_loader = privacy_engine.make_private_with_epsilon(\n",
    "            module=model,\n",
    "            optimizer=optimizer,\n",
    "            data_loader=train_loader,\n",
    "            noise_multiplier = 1,\n",
    "            epochs=EPOCHS,\n",
    "            target_epsilon=3,\n",
    "            target_delta=DELTA,\n",
    "            max_grad_norm=GU250['clip'][i],\n",
    "            PLRV_args=args,\n",
    "    )\n",
    "\n",
    "    plrv_report_acc = []\n",
    "    plrv_report_ep = []\n",
    "\n",
    "    for epoch in tqdm(range(EPOCHS), desc=\"Epoch\", unit=\"epoch\"):\n",
    "        acc, ep = train(model, train_loader, optimizer, epoch + 1, device)\n",
    "        plrv_report_acc.append(acc)\n",
    "        plrv_report_ep.append(ep)\n",
    "\n",
    "    acc_plrv_2.append(plrv_report_ep)\n",
    "    del model\n",
    "    del optimizer\n",
    "    #del results\n",
    "#    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3144a75d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "acc_plrv_2 = []\n",
    "from torchvision.models.mobilenet import mobilenet_v2\n",
    "for i in [65546, 38231]:\n",
    "    torch.cuda.empty_cache()\n",
    "    args ={\n",
    "        \"a1\":1,\n",
    "        \"a3\":1,\n",
    "        \"a4\":1,\n",
    "        \"lam\":1,\n",
    "        \"moment\":1,\n",
    "        \"theta\":GU250['theta'][i],\n",
    "        'k':GU250['k'][i],\n",
    "        'mu':0,\n",
    "        'sigma':0.5,\n",
    "        'a':GU250['a'][i],\n",
    "        'b':GU250['b'][i],\n",
    "        'u':1,\n",
    "        'l':0.1,\n",
    "        'epsilon':1,\n",
    "        'max_grad_norm': GU250['clip'][i],\n",
    "        'gamma':True,\n",
    "        'uniform':True,\n",
    "        'truncnorm':False,\n",
    "    }\n",
    "    print(GU250['theta'][i])\n",
    "    EPOCHS = 5\n",
    "    BATCH_SIZE = 119\n",
    "    #print()\n",
    "    from torchvision.datasets import MNIST\n",
    "    import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "\n",
    "    DATA_ROOT = '../mnist'\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    train_dataset = CIFAR10(\n",
    "        root=DATA_ROOT, train=True, download=True, transform=transform)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "    )\n",
    "\n",
    "    test_dataset = CIFAR10(\n",
    "        root=DATA_ROOT, train=False, download=True, transform=transform)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    \n",
    "    #gen_args = find_values(15, i)\n",
    "    runs = []\n",
    "    trun = []\n",
    "\n",
    "    model = mobilenet_v2(num_classes=10)\n",
    "    #model.classifier[1] = torch.nn.Linear(in_features=model.classifier[1].in_features, out_features=10)\n",
    "    #model.conv1 = nn.Conv2d(1, 28, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    #model.load_state_dict(dic)\n",
    "    #model.train()\n",
    "\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = ModuleValidator.fix(model)\n",
    "    model = model.to(device)\n",
    "\n",
    "    privacy_engine = PrivacyEngine(accountant = 'rdp_plrv')\n",
    "\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=LR)\n",
    "    print(\"Begin training \" + str(i))\n",
    "    model, optimizer, train_loader = privacy_engine.make_private_with_epsilon(\n",
    "            module=model,\n",
    "            optimizer=optimizer,\n",
    "            data_loader=train_loader,\n",
    "            noise_multiplier = 1,\n",
    "            epochs=EPOCHS,\n",
    "            target_epsilon=3,\n",
    "            target_delta=DELTA,\n",
    "            max_grad_norm=GU250['clip'][i],\n",
    "            PLRV_args=args,\n",
    "    )\n",
    "\n",
    "    plrv_report_acc = []\n",
    "    plrv_report_ep = []\n",
    "    privacy_engine.accountant.sample_rate = 1/len(train_loader)\n",
    "    epsis = []\n",
    "    for j in range(len(train_loader)*5):\n",
    "        privacy_engine.accountant.history = [[args, j]]\n",
    "        epsis.append(privacy_engine.get_epsilon(10e-10))\n",
    "    acc_plrv_2.append(epsis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de25fcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_plrv_2 = [[(10.827088,0.96580), \n",
    "              (27.407932,1.96362),\n",
    "              (41.499464,2.96142),\n",
    "              (47.529392,3.95914),\n",
    "              (52.126053,4.95723),\n",
    "              ], [(10.192589,0.10905),\n",
    "              (16.807797,0.20513),\n",
    "              (27.030008,0.30121),\n",
    "              (38.087848,0.39730),\n",
    "              (46.760616,0.49338),]\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e8051f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(acc_plrv_2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14e64d9-24a3-4d49-9cc6-5f6caff1ccca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "acc_plrv = []\n",
    "for i in range(1, len(GU250), int(len(GU250)/10)):\n",
    "    torch.cuda.empty_cache()\n",
    "    args ={\n",
    "        \"a1\":1,\n",
    "        \"a3\":1,\n",
    "        \"a4\":1,\n",
    "        \"lam\":1,\n",
    "        \"moment\":1,\n",
    "        \"theta\":GU250['theta'][i],\n",
    "        'k':GU250['k'][i],\n",
    "        'mu':0,\n",
    "        'sigma':0.5,\n",
    "        'a':GU250['a'][i],\n",
    "        'b':GU250['b'][i],\n",
    "        'u':1,\n",
    "        'l':0.1,\n",
    "        'epsilon':1,\n",
    "        'max_grad_norm': GU250['b'][i],\n",
    "        'gamma':True,\n",
    "        'uniform':False,\n",
    "        'truncnorm':False,\n",
    "    }\n",
    "    \n",
    "    #gen_args = find_values(15, i)\n",
    "    runs = []\n",
    "    trun = []\n",
    "\n",
    "    model = mobilenet_v2(num_classes=10)\n",
    "    #model.classifier[1] = torch.nn.Linear(in_features=model.classifier[1].in_features, out_features=10)\n",
    "    #model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "    #model.load_state_dict(dic)\n",
    "    #model.train()\n",
    "\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = ModuleValidator.fix(model)\n",
    "    model = model.to(device)\n",
    "\n",
    "    privacy_engine = PrivacyEngine(accountant = 'rdp_plrv')\n",
    "\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=LR)\n",
    "    print(\"Begin training \" + str(i))\n",
    "    model, optimizer, train_loader = privacy_engine.make_private_with_epsilon(\n",
    "            module=model,\n",
    "            optimizer=optimizer,\n",
    "            data_loader=train_loader,\n",
    "            noise_multiplier = 1,\n",
    "            epochs=10,\n",
    "            target_epsilon=0.15,\n",
    "            target_delta=DELTA,\n",
    "            max_grad_norm=GU250['clip'][i],\n",
    "            PLRV_args=args,\n",
    "    )\n",
    "\n",
    "    plrv_report_acc = []\n",
    "    plrv_report_ep = []\n",
    "\n",
    "    for epoch in tqdm(range(5), desc=\"Epoch\", unit=\"epoch\"):\n",
    "        acc, ep = train(model, train_loader, optimizer, epoch + 1, device)\n",
    "        plrv_report_acc.append(acc)\n",
    "        plrv_report_ep.append(ep)\n",
    "\n",
    "    acc_plrv.append((G250['distortion'][i], test(model, test_loader, device)))\n",
    "    del model\n",
    "    del optimizer\n",
    "    #del results\n",
    "#    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b566b3-23ad-4f3f-8110-77e3a7dcd7b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "acc_plrv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e14de1-6d68-4f93-a5e5-ca223a9f102f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "g_eps = pd.read_csv('../arguments/gaussian_eps.csv', names = ['eps'])\n",
    "g_dist = pd.read_csv('../arguments/gaussian_dist.csv', names = ['distortion'])\n",
    "g_clip = pd.read_csv('../arguments/gaussian_clip.csv', names = ['clip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37e0357-8abb-4e3a-8057-2a1f8ec567b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "g_clip = g_clip.dropna()\n",
    "g_clip = g_clip.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c17f880-d8b1-4879-8d6b-7eff2cc64cff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "acc_rdp = []\n",
    "from torchvision.models.mobilenet import mobilenet_v2\n",
    "for i in [0.5, 5]:\n",
    "    print(i)\n",
    "    #gen_args = find_values(15, i)\n",
    "    runs = []\n",
    "    trun = []\n",
    "\n",
    "    model = mobilenet_v2(num_classes=10)\n",
    "    #model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "    #model.load_state_dict(dic)\n",
    "    #model.train()\n",
    "\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = ModuleValidator.fix(model)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    privacy_engine = PrivacyEngine(accountant = 'rdp')\n",
    "\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=LR)\n",
    "    print(\"Begin training \" + str(i))\n",
    "    model, optimizer, train_loader = privacy_engine.make_private_with_epsilon(\n",
    "            module=model,\n",
    "            optimizer=optimizer,\n",
    "            data_loader=train_loader,\n",
    "            #noise_multiplier = 1,\n",
    "            epochs=5,\n",
    "            target_epsilon=i,\n",
    "            target_delta=1e-10,\n",
    "            max_grad_norm=10,\n",
    "            #PLRV_args=convert_params(gen_args),\n",
    "    )\n",
    "\n",
    "    plrv_report_acc = []\n",
    "    plrv_report_ep = []\n",
    "\n",
    "    for epoch in tqdm(range(5), desc=\"Epoch\", unit=\"epoch\"):\n",
    "        acc, ep = train(model, train_loader, optimizer, epoch + 1, device)\n",
    "        plrv_report_acc.append(acc)\n",
    "        plrv_report_ep.append(ep)\n",
    "\n",
    "    acc_rdp.append((plrv_report_acc, plrv_report_ep))\n",
    "    del model\n",
    "    del optimizer\n",
    "    #del results\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    privacy_engine.accountant.sample_rate = 1/len(train_loader)\n",
    "    epsis = []\n",
    "    for i in range(len(train_loader)*5):\n",
    "        privacy_engine.accountant.history = [[args, i]]\n",
    "        epsis.append(privacy_engine.get_epsilon(10e-10))\n",
    "    acc_rdp.append(epsis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afe8277",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from opacus.accountants.utils import get_noise_multiplier\n",
    "acc_rdp = []\n",
    "from torchvision.models.mobilenet import mobilenet_v2\n",
    "for i in [0.5, 5]:\n",
    "    print(i)\n",
    "    #gen_args = find_values(15, i)\n",
    "    runs = []\n",
    "    trun = []\n",
    "\n",
    "    model = mobilenet_v2(num_classes=10)\n",
    "    #model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "    #model.load_state_dict(dic)\n",
    "    #model.train()\n",
    "\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = ModuleValidator.fix(model)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    privacy_engine = PrivacyEngine(accountant = 'rdp')\n",
    "\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=LR)\n",
    "    print(\"Begin training \" + str(i))\n",
    "    model, optimizer, train_loader = privacy_engine.make_private_with_epsilon(\n",
    "            module=model,\n",
    "            optimizer=optimizer,\n",
    "            data_loader=train_loader,\n",
    "            #noise_multiplier = 1,\n",
    "            epochs=5,\n",
    "            target_epsilon=i,\n",
    "            target_delta=1e-10,\n",
    "            max_grad_norm=10,\n",
    "            #PLRV_args=convert_params(gen_args),\n",
    "    )\n",
    "\n",
    "    plrv_report_acc = []\n",
    "    plrv_report_ep = []\n",
    "    \n",
    "    nm = noise_multiplier=get_noise_multiplier(\n",
    "                target_epsilon=i,\n",
    "                target_delta=DELTA,\n",
    "                sample_rate=1/len(train_loader),\n",
    "                epochs=EPOCHS,\n",
    "                accountant=privacy_engine.accountant.mechanism(),\n",
    "            )\n",
    "    print(nm)\n",
    "    #privacy_engine.accountant.sample_rate = BATCH_SIZE/50000\n",
    "    epsis = []\n",
    "    for j in range(len(train_loader)*5):\n",
    "        privacy_engine.accountant.history = [(nm, 1/len(train_loader), j)]\n",
    "        epsis.append(privacy_engine.get_epsilon(DELTA))\n",
    "    acc_rdp.append(epsis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae904d1",
   "metadata": {},
   "outputs": [],
   "source": [
    " acc_rdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9876e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_rdp = [[(10.116650,0.43046), \n",
    "              (10.711590,0.44728),\n",
    "              (10.492322,0.46410),\n",
    "              (10.288952,0.48092),\n",
    "              (10.566023,0.49774),\n",
    "              ], [(10.417261,4.40004),\n",
    "              (10.726745,4.60714),\n",
    "              (11.139498,4.75362),\n",
    "              (12.236695,4.87810),\n",
    "              (12.436983,4.99017),]\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e5a83c-e729-448c-8dfc-833a2c798182",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "model = models.resnet18(num_classes=10)\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "model = ModuleValidator.fix(model)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "privacy_engine = PrivacyEngine(accountant = 'rdp_plrv')\n",
    "\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=LR)\n",
    "model, optimizer, train_loader = privacy_engine.make_private_with_epsilon(\n",
    "            module=model,\n",
    "            optimizer=optimizer,\n",
    "            data_loader=train_loader,\n",
    "            noise_multiplier = 1,\n",
    "            epochs=10,\n",
    "            target_epsilon=0.15,\n",
    "            target_delta=DELTA,\n",
    "            max_grad_norm=GU250['clip'][i],\n",
    "            PLRV_args=args,\n",
    "    )\n",
    "dic = model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71412da4-6223-4f15-8c5e-e26f1da511ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b1a6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_x = [i[0] for i in acc_plrv_2]\n",
    "acc_y = [i[1] for i in acc_plrv_2]\n",
    "dist_g = [i[0] for i in acc_rdp]\n",
    "acc_g = [i[1] for i in acc_rdp]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel(\"distortion\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"distortion vs accuracy\")\n",
    "plt.yscale('log')\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.plot(dist_x, acc_y, 'bo-', label=\"PLRV\")\n",
    "ax1.set_ylabel(\"Accuracy\")\n",
    "#ax1.set_yscale('log')\n",
    "ax2 = ax1.twiny()\n",
    "ax2.plot(dist_g, acc_g, 'ro-', label=\"Guassian\")\n",
    "#ax2.set_yscale('log')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8470d76b-c3c9-4092-a258-82fcf93419e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "acc_plrv_2.sort()\n",
    "acc_rdp.sort()\n",
    "dist_x = [i[2] for i in acc_plrv_2]\n",
    "acc_y = [i[1] for i in acc_plrv_2]\n",
    "dist_g = [i[0] for i in acc_rdp]\n",
    "acc_g = [i[1] for i in acc_rdp]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel(\"distortion\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"distortion vs accuracy\")\n",
    "plt.yscale('log')\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.plot(dist_x, acc_y, 'bo-', label=\"PLRV\")\n",
    "ax1.set_ylabel(\"Accuracy\")\n",
    "ax1.set_xscale('log')\n",
    "ax2 = ax1.twiny()\n",
    "ax2.plot(dist_g, acc_g, 'ro-', label=\"Guassian\")\n",
    "#ax2.set_yscale('log')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72c4d84-868d-4345-b497-ceee9b77bf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "#acc_plrv_2.sort()\n",
    "#acc_rdp.sort()\n",
    "x_vals = range(1,6)\n",
    "print(acc_plrv_2)\n",
    "plrv1 = [i[1] for i in acc_plrv_2[0]]\n",
    "plrv2 = [i[1] for i in acc_plrv_2[1]]\n",
    "print(acc_rdp)\n",
    "g1 = [i[1] for i in acc_rdp[0]]\n",
    "g2 = [i[1] for i in acc_rdp[1]]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Epsilon\")\n",
    "plt.title(\"Epochs vs Epsilon\")\n",
    "#plt.plot(x_vals, plrv1, 'b+-', label=\"PLRV 45% accuracy\")\n",
    "#plt.plot(x_vals, plrv2, 'bo--', label=\"PLRV 10% accuracy\")\n",
    "plt.plot(x_vals, g1, 'ro-', label=\"gaussian ϵ=0.5\")\n",
    "#plt.plot(x_vals, g2, 'r+-', label=\"gaussian ϵ=5\")\n",
    "plt.plot(x_vals, plrv2, 'bo-', label=\"PLRV  ϵ=0.5\")\n",
    "#plt.plot(x_vals, plrv1, 'b+-', label=\"PLRV  ϵ=5\")\n",
    "#plt.yticks(np.logspace(0, 200, 5)) \n",
    "#plt.yscale(\"log\")\n",
    "#plt.gca().yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, _: f'{x:.2f}'))\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa389250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "#acc_plrv_2.sort()\n",
    "#acc_rdp.sort()\n",
    "x_vals = range(1,2106)\n",
    "\n",
    "plrv1 = acc_plrv_2[0]\n",
    "plrv2 = acc_plrv_2[1]\n",
    "g2 = acc_rdp[1]\n",
    "g1 = acc_rdp[0]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"Epsilon\")\n",
    "plt.title(\"Steps vs Epsilon\")\n",
    "#plt.plot(x_vals, plrv1, 'b+-', label=\"PLRV 45% accuracy\")\n",
    "#plt.plot(x_vals, plrv2, 'bo--', label=\"PLRV 10% accuracy\")\n",
    "plt.plot(x_vals, g1, 'r--', label=\"gaussian ϵ=0.5\")\n",
    "plt.plot(x_vals, g2, 'r-', label=\"gaussian ϵ=5\")\n",
    "plt.plot(x_vals, plrv2, 'b--', label=\"PLRV  ϵ=0.5\")\n",
    "plt.plot(x_vals, plrv1, 'b-', label=\"PLRV  ϵ=5\")\n",
    "#plt.yticks(np.logspace(0, 200, 5)) \n",
    "#plt.yscale(\"log\")\n",
    "#plt.gca().yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, _: f'{x:.2f}'))\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a4356c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "#acc_plrv_2.sort()\n",
    "#acc_rdp.sort()\n",
    "x_vals = range(1,len(train_loader)+1)\n",
    "\n",
    "plrv1 = acc_plrv_2[0][0:len(train_loader)]\n",
    "plrv2 = acc_plrv_2[1][0:len(train_loader)]\n",
    "g2 = acc_rdp[1][0:len(train_loader)]\n",
    "g1 = acc_rdp[0][0:len(train_loader)]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"Epsilon\")\n",
    "plt.title(\"Steps vs Epsilon\")\n",
    "#plt.plot(x_vals, plrv1, 'b+-', label=\"PLRV 45% accuracy\")\n",
    "#plt.plot(x_vals, plrv2, 'bo--', label=\"PLRV 10% accuracy\")\n",
    "plt.plot(x_vals, g1, 'r--', label=\"gaussian ϵ=0.5\")\n",
    "plt.plot(x_vals, g2, 'r-', label=\"gaussian ϵ=5\")\n",
    "plt.plot(x_vals, plrv2, 'b--', label=\"PLRV  ϵ=0.5\")\n",
    "plt.plot(x_vals, plrv1, 'b-', label=\"PLRV  ϵ=5\")\n",
    "#plt.yticks(np.logspace(0, 200, 5)) \n",
    "#plt.yscale(\"log\")\n",
    "#plt.gca().yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, _: f'{x:.2f}'))\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7626b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "#acc_plrv_2.sort()\n",
    "#acc_rdp.sort()\n",
    "x_vals = range(1,len(train_loader)+1)\n",
    "\n",
    "plrv1 = acc_plrv_2[0][0:len(train_loader)]\n",
    "plrv2 = acc_plrv_2[1][0:len(train_loader)]\n",
    "g2 = acc_rdp[1][0:len(train_loader)]\n",
    "g1 = acc_rdp[0][0:len(train_loader)]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"Epsilon\")\n",
    "plt.title(\"Steps vs Epsilon\")\n",
    "#plt.plot(x_vals, plrv1, 'b+-', label=\"PLRV 45% accuracy\")\n",
    "#plt.plot(x_vals, plrv2, 'bo--', label=\"PLRV 10% accuracy\")\n",
    "plt.plot(x_vals, g1, 'r--', label=\"gaussian ϵ=0.5\")\n",
    "#plt.plot(x_vals, g2, 'r-', label=\"gaussian ϵ=5\")\n",
    "plt.plot(x_vals, plrv2, 'b--', label=\"PLRV  ϵ=0.5\")\n",
    "#plt.plot(x_vals, plrv1, 'b-', label=\"PLRV  ϵ=5\")\n",
    "#plt.yticks(np.logspace(0, 200, 5)) \n",
    "#plt.yscale(\"log\")\n",
    "#plt.gca().yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, _: f'{x:.2f}'))\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db69866d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d23362f-bed5-4c37-9ac4-fc61fd00a3b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "acc_plrv = []\n",
    "for i in range(1, 11):\n",
    "    gen_args = find_values(13, i)\n",
    "    runs = []\n",
    "    trun = []\n",
    "\n",
    "    #model = models.resnet18(num_classes=10)\n",
    "    #model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "    model.load_state_dict(dic)\n",
    "    model.train()\n",
    "\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    privacy_engine = PrivacyEngine(accountant = 'rdp_plrv')\n",
    "\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=LR)\n",
    "    print(\"Begin training \" + str(i))\n",
    "    model, optimizer, train_loader = privacy_engine.make_private_with_epsilon(\n",
    "            module=model,\n",
    "            optimizer=optimizer,\n",
    "            data_loader=train_loader,\n",
    "            noise_multiplier = 1,\n",
    "            epochs=EPOCHS,\n",
    "            target_epsilon=0.15,\n",
    "            target_delta=DELTA,\n",
    "            max_grad_norm=i+1,\n",
    "            PLRV_args=convert_params(gen_args),\n",
    "    )\n",
    "\n",
    "    plrv_report_acc = []\n",
    "    plrv_report_ep = []\n",
    "\n",
    "    for epoch in tqdm(range(1), desc=\"Epoch\", unit=\"epoch\"):\n",
    "        acc, ep = train(model, train_loader, optimizer, epoch + 1, device)\n",
    "        plrv_report_acc.append(acc)\n",
    "        plrv_report_ep.append(ep)\n",
    "\n",
    "    acc_plrv.append(test(model, test_loader, device))\n",
    "#    del model\n",
    "    del optimizer\n",
    "    #del results\n",
    "#    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba4c6e1-dadd-4cc0-8aa9-6717a5847a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "3**False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300d8669-d93e-4ae5-9e14-58beadd4dbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model as lm\n",
    "\n",
    "lm.LinearRegression().fit(X, plrv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0ab683",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [50000/120*1,50000/120*2,50000/120*3,50000/120*4,50000/120*5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9111ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to calculate the slope and intercept of the linear regression line\n",
    "def linear_regression(x, y):\n",
    "    # Using the formula for linear regression: y = mx + b\n",
    "    # m = (N * Σ(xy) - Σx * Σy) / (N * Σ(x^2) - (Σx)^2)\n",
    "    # b = (Σy - m * Σx) / N\n",
    "\n",
    "    N = len(x)\n",
    "    Σx = np.sum(x)\n",
    "    Σy = np.sum(y)\n",
    "    Σxy = np.sum(x * y)\n",
    "    Σx2 = np.sum(x ** 2)\n",
    "\n",
    "    # Calculate slope (m) and intercept (b)\n",
    "    m = (N * Σxy - Σx * Σy) / (N * Σx2 - Σx ** 2)\n",
    "    b = (Σy - m * Σx) / N\n",
    "\n",
    "    return m, b\n",
    "\n",
    "# Function to predict y values based on the linear model\n",
    "def predict(x, m, b):\n",
    "    return m * x + b\n",
    "\n",
    "# Example input data (x and y)\n",
    "x = np.array(X)\n",
    "y = np.array(plrv1)\n",
    "\n",
    "# Calculate the slope and intercept\n",
    "m, b = linear_regression(x, y)\n",
    "\n",
    "# Display the result\n",
    "print(f\"Linear regression equation: y = {m:.2f}x + {b:.2f}\")\n",
    "\n",
    "# Predict y values based on the regression line\n",
    "y_pred = predict(x, m, b)\n",
    "\n",
    "# Plot the data points and the regression line\n",
    "plt.scatter(x, y, color='blue')\n",
    "plt.plot(x, y_pred, color='red', label=f'Regression line: y = {m:.2E}x + {b:.2f}')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('PLRV Linear Regression')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcccce8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(X)\n",
    "y = np.array(plrv2)\n",
    "\n",
    "# Calculate the slope and intercept\n",
    "m, b = linear_regression(x, y)\n",
    "\n",
    "# Display the result\n",
    "print(f\"Linear regression equation: y = {m:.2f}x + {b:.2f}\")\n",
    "\n",
    "# Predict y values based on the regression line\n",
    "y_pred = predict(x, m, b)\n",
    "\n",
    "# Plot the data points and the regression line\n",
    "plt.scatter(x, y, color='blue', label='Data points')\n",
    "plt.plot(x, y_pred, color='red', label=f'Regression line: y = {m:.2E}x + {b:.2f}')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Linear Regression')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760697f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(X)\n",
    "y = np.log(np.array(g1))\n",
    "\n",
    "# Calculate the slope and intercept\n",
    "m, b = linear_regression(x, y)\n",
    "\n",
    "# Display the result\n",
    "print(f\"Linear regression equation: y = {m:.2E}x + {b:.2f}\")\n",
    "\n",
    "# Predict y values based on the regression line\n",
    "y_pred = predict(x, m, b)\n",
    "\n",
    "# Plot the data points and the regression line\n",
    "plt.scatter(x, y, color='blue', label='Data points')\n",
    "plt.plot(x, y_pred, color='red', label=f'Regression line: y = {m:.2f}ln(x) + {b:.2f}')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Linear Regression')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5924fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.log(np.array(X))\n",
    "y = np.array(g2)\n",
    "\n",
    "# Calculate the slope and intercept\n",
    "m, b = linear_regression(x, y)\n",
    "\n",
    "# Display the result\n",
    "print(f\"Linear regression equation: y = {m:.2E}ln(x) + {b:.2f}\")\n",
    "\n",
    "# Predict y values based on the regression line\n",
    "y_pred = predict(x, m, b)\n",
    "\n",
    "# Plot the data points and the regression line\n",
    "plt.scatter(x, y, color='blue', label='Data points')\n",
    "plt.plot(x, y_pred, color='red', label=f'Regression line: y = {m:.2f}ln(x) + {b:.2f}')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Linear Regression')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f673911",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(acc_plrv_2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82be6ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "roberta = torch.hub.load('pytorch/fairseq', 'roberta.large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184240e4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Question NLI dataset\n",
    "dataset = load_dataset(\"snli\")\n",
    "# Load the Roberta tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Preprocess the data\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['premise'], examples['hypothesis'], truncation=True, padding=True)\n",
    "\n",
    "# Apply preprocessing to train, validation, and test sets\n",
    "tokenized_datasets = dataset.map(preprocess_function, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets = tokenized_datasets.filter(lambda example: example['labels'] != -1)\n",
    "\n",
    "# Load the Roberta model for sequence classification\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=3)\n",
    "\n",
    "# Define the metric for evaluation\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = torch.argmax(torch.tensor(predictions), dim=-1)\n",
    "    return {\"accuracy\": accuracy_score(labels, predictions)}\n",
    "\n",
    "# Set up training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",# Evaluate after every epoch\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=3,\n",
    "    logging_dir=\"./logs\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=lambda data: tokenizer.pad(data, padding=True, return_tensors=\"pt\")  # Use dynamic padding\n",
    ")\n",
    "\n",
    "trainer.args.device = \"cpu\"\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.evaluate(tokenized_datasets[\"test\"])\n",
    "\n",
    "# Print the final test results\n",
    "print(f\"Test results: {test_results}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa668141",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(tokenized_datasets['train']['labels']))  # Check label values in the training set\n",
    "print(set(tokenized_datasets['validation']['labels']))  # Check label values in the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0504e06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(tokenized_datasets['train']['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357b0c68",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datasets import load_dataset\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "\n",
    "# Ensure that the model runs on the CPU\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# Load the Question NLI dataset\n",
    "dataset = load_dataset(\"snli\")\n",
    "\n",
    "# Load the Roberta tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Preprocess the data\n",
    "def preprocess_function(examples):\n",
    "    # Tokenize the premise and hypothesis\n",
    "    return tokenizer(\n",
    "        examples['premise'], \n",
    "        examples['hypothesis'], \n",
    "        truncation=True, \n",
    "        padding='max_length', \n",
    "        max_length=512  # Ensure input size consistency\n",
    "    )\n",
    "\n",
    "# Apply preprocessing to train, validation, and test sets\n",
    "tokenized_datasets = dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# Ensure that the labels are correctly passed as \"labels\" in the dataset\n",
    "# In SNLI, the labels are already present in the 'label' field. We rename it to 'labels'\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "\n",
    "# Remove samples with label -1 (if they exist)\n",
    "tokenized_datasets = tokenized_datasets.filter(lambda example: example['labels'] != -1)\n",
    "\n",
    "# Check to ensure there are no remaining -1 labels\n",
    "print(set(tokenized_datasets['train']['labels']))  # Check the label values after filtering\n",
    "\n",
    "# Load the Roberta model for sequence classification\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=3)\n",
    "\n",
    "# Move the model to CPU\n",
    "#model.to(device)\n",
    "\n",
    "# Define the metric for evaluation\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = torch.argmax(torch.tensor(predictions), dim=-1)\n",
    "    return {\"accuracy\": accuracy_score(labels, predictions)}\n",
    "\n",
    "# Set up training arguments to run on CPU\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",  # Evaluate after every epoch\n",
    "    save_strategy=\"epoch\",        # Save after every epoch\n",
    "    per_device_train_batch_size=8,  # Lower batch size for CPU\n",
    "    per_device_eval_batch_size=8,   # Lower batch size for CPU\n",
    "    num_train_epochs=3,\n",
    "    logging_dir=\"./logs\",\n",
    "    load_best_model_at_end=True,\n",
    "    use_cpu=False,  # Disable CUDA to force CPU\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.evaluate(tokenized_datasets[\"test\"])\n",
    "\n",
    "# Print the final test results\n",
    "print(f\"Test results: {test_results}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c227e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets transformers[torch] scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bda392d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
